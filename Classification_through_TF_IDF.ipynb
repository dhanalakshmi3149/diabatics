{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNesMFMEKOiDk3Nw7KCHIEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanalakshmi3149/diabatics/blob/main/Classification_through_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FViv_190v2HD",
        "outputId": "dbfaab31-d696-45cf-cf5d-545aef35bfd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Start Spark Session\n",
        "spark = SparkSession.builder.appName(\"DocumentClassification\").getOrCreate()\n",
        "\n",
        "# Fetch 20 Newsgroups Data\n",
        "newsgroups = fetch_20newsgroups(subset='all')\n",
        "\n",
        "# Convert the dataset to a DataFrame for PySpark processing\n",
        "data = pd.DataFrame({'text': newsgroups.data, 'category': newsgroups.target})\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# Show some details about the data\n",
        "print(f\"Total number of documents: {len(newsgroups.data)}\")\n",
        "print(f\"Categories: {newsgroups.target_names}\")\n",
        "print(f\"Number of categories: {len(newsgroups.target_names)}\")\n",
        "\n",
        "# Display the distribution of categories\n",
        "category_counts = df.groupBy('category').count().toPandas()\n",
        "print(\"Category distribution before filtering (25%):\")\n",
        "print(category_counts)\n",
        "\n",
        "# Filter 25% of documents from each category\n",
        "df_sampled = df.sample(withReplacement=False, fraction=0.25, seed=42)\n",
        "\n",
        "# Show the number of documents after sampling\n",
        "total_documents_after_sampling = df_sampled.count()\n",
        "print(f\"Total number of documents after sampling: {total_documents_after_sampling}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf8P3voJv3VX",
        "outputId": "417395b9-2b06-474c-b8e8-a744984f3600"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of documents: 18846\n",
            "Categories: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of categories: 20\n",
            "Category distribution before filtering (25%):\n",
            "    category  count\n",
            "0         19    628\n",
            "1          0    799\n",
            "2          7    990\n",
            "3          6    975\n",
            "4          9    994\n",
            "5         17    940\n",
            "6          5    988\n",
            "7          1    973\n",
            "8         10    999\n",
            "9          3    982\n",
            "10        12    984\n",
            "11         8    996\n",
            "12        11    991\n",
            "13         2    985\n",
            "14         4    963\n",
            "15        13    990\n",
            "16        18    775\n",
            "17        14    987\n",
            "18        15    997\n",
            "19        16    910\n",
            "Total number of documents after sampling: 4773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for Document Classification\n",
        "\n",
        "# Step 1: Tokenize the text\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "\n",
        "# Step 2: Apply HashingTF\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"raw_features\", numFeatures=1000)\n",
        "\n",
        "# Step 3: Compute IDF (Inverse Document Frequency)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "\n",
        "# Step 4: Convert category labels to numerical labels\n",
        "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
        "\n",
        "# Step 5: Define the classifier (Logistic Regression in this case)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Set up the pipeline with all the stages\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, indexer, lr])\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "train_data, test_data = df_sampled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 6: Train the model using the pipeline\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Step 7: Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Show some of the predictions\n",
        "predictions.select(\"text\", \"category\", \"prediction\").show(5, truncate=False)\n",
        "\n",
        "# Step 8: Evaluate the model's accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "# Display the accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAR2ftbLv7QW",
        "outputId": "ff411327-2c33-40f1-e4d7-919400969e4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
            "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |category|prediction|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
            "| zaphod.mps.ohio-state.edu!wupost!uunet!olivea!sgigate!odin!fido!solntze.wpd.sgi.com!livesey\\nSubject: Re: <Political Atheists?\\nFrom: livesey@solntze.wpd.sgi.com (Jon Livesey)\\n <1p6rgcINNhfb@gap.caltech.edu> <1p88fi$4vv@fido.asd.sgi.com> \\n <1993Mar30.051246.29911@blaze.cs.jhu.edu> <1p8nd7$e9f@fido.asd.sgi.com> <1pa0stINNpqa@gap.caltech.edu> <1pan4f$b6j@fido.asd.sgi.com>\\nOrganization: sgi\\nNNTP-Posting-Host: solntze.wpd.sgi.com\\nLines: 20\\n\\nIn article <1pieg7INNs09@gap.caltech.edu>, keith@cco.caltech.edu (Keith Allan Schneider) writes:\\n|> livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\\n|> \\n|> >Now along comes Mr Keith Schneider and says \"Here is an \"objective\\n|> >moral system\".  And then I start to ask him about the definitions\\n|> >that this \"objective\" system depends on, and, predictably, the whole\\n|> >thing falls apart.\\n|> \\n|> It only falls apart if you attempt to apply it.  This doesn't mean that\\n|> an objective system can't exist.  It just means that one cannot be\\n|> implemented.\\n\\nIt's not the fact that it can't exist that bothers me.   It's \\nthe fact that you don't seem to be able to define it.\\n\\nIf I wanted to hear about indefinable things that might in\\nprinciple exist as long as you don't think about them too\\ncarefully, I could ask a religious person, now couldn't I?\\n\\njon.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |0       |17.0      |\n",
            "|Distribution: world\\nFrom: Mario_Murphy@bmug.org\\nOrganization: BMUG, Inc.\\nSubject: Re: SAD MAC CODE 0F0064 ???\\nLines: 12\\n\\nI believe that that would be the same as a system error #64. Since there is no\\nerror #64, then I would guess that it would be a -64 error. Which is a font\\nmanager error of \"error during font declairation\".\\n\\nI would assume that the system that's on the floppy that you are trying start\\nup on has a corrupted font in it, or something like that.\\n\\nMario Murphy\\n\\n**** From Planet BMUG, the FirstClass BBS of BMUG.  The message contained in\\n**** this posting does not in any way reflect BMUG's official views.\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |4       |13.0      |\n",
            "|From:  (Sean Garrison)\\nSubject: Re: Bonilla\\nNntp-Posting-Host: berkeley-kstar-node.net.yale.edu\\nOrganization: Yale Univeristy\\nLines: 37\\n\\nIn article <1993Apr17.213553.2181@organpipe.uug.arizona.edu>,\\nkrueger@helium.gas.uug.arizona.edu (theodore r krueger) wrote:\\n \\n> Isn't it funny that  a white person calls comeone a \"nigger\" and gets banned \\n> for a year, but a black person calls someone a \"faggot\" and there is no \\n> consequence?\\n\\n> Ted\\n\\n\\nTed, you're missing a vital point.  As Roger Lustig pointed out in a\\nprevious response, the reason why Schott was banned from baseball was\\nbecause she had been known to call and think in a racially biased manner on\\na constant basis.  Such thoughts affected her hiring practices.  Bonilla,\\non the other hand, was found to have mentioned this one word a single time.\\n If he had been known to go around, criticizing homosexuals, it would be a\\ndifferent story.  Furthermore, he is merely an athlete.  He doesn't have to\\nhire anyone as Schott had to do.  Dave Pallone, the former NL umpire who is\\nan admitted homosexual, has decided to assist in a protest before a Mets\\ngame at Shea.  He, like you, thinks that Bonilla should be suspended from\\nbaseball.  Pallone is hoping for a year's suspension.  In my opinion,\\nthat's downright ludicrous.  As Howie Rose on WFAN said, if you start\\nsuspending athletes who have mentioned a derogatory word even a single time\\nunder whatever conditions, then you'd probably have enough people remaining\\nto play a three-on-three game.  Now, honestly, if you truly analyze the\\ndifferences between the two cases that you bring up in your article, I\\nwould think that you'd reconsider your thoughts.\\n\\n\\n                                    -Sean\\n\\n\\n\\n*******************************************************************************\\n  \"Behind the bag!\"\\n            - Vin Scully\\n*******************************************************************************\\n|9       |3.0       |\n",
            "|From: \"Derrick J. Brashear\" <db74+@andrew.cmu.edu>\\nSubject: mouseless operation in ol{v}wm\\nOrganization: Sophomore, Civil Engineering, Carnegie Mellon, Pittsburgh, PA\\nLines: 11\\nNNTP-Posting-Host: po5.andrew.cmu.edu\\n\\nMouseless operation is documented in the man pages for olwm and olvwm...\\nHowever, I can't get it to work in either.\\nI have this line in my .Xdefaults:\\nOpenWindows.KeyboardCommands:           Full\\n\\nThat should do it...\\nI haven't rebound the keys.\\nAm I missing something?\\n\\n-D\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |5       |2.0       |\n",
            "|From: \"Mohammad Al-Ansari\" <alansari@mango.ucs.indiana.edu>\\nSubject: Re: 17\" Monitors\\nOrganization: Indiana University Computer Science, Bloomington\\nLines: 30\\n\\nIn article <1993Apr10.082253.19597@uxmail.ust.hk> cs_ngfo@uxmail.ust.hk (Forrest Normandy) writes:\\n>I want to buy a 17\" monitor, any comment on Nanno T560i, NEC 5FG,\\n>SII 17\" ???\\n>\\n>Thanks a lot.\\n>\\n>--\\n>________________________________________________________________________\\n> Forrest Normandy                 |     The Hong Kong University of\\n> Internet : cs_ngfo@stu.ust.hk    |       Science and Technology\\n> E-mail   : cs_ngfo@uxmail.ust.hk |    Department of Computer Science\\n> Phone    : (852) 358-8631 Rm 608 |------------------------------------\\n> Paging   : 1128635 a/c 4860      | Rm 608, UG Hall 4, HKUST, Hong Kong\\n>------------------------------------------------------------------------\\n\\n\\nWindows Sources Magazine reviewed a number of 17\" monitors recently\\nand they too said that the Nanao T560i was the best monitor to get if\\nyou had the money. But they also said that the Mitsubishi Diamond Pro\\n17 is the next best choice and that it has superb picture quality.\\nThis monitor can be had for around $1070.\\n\\nHas anyone actually seen any of these? I am also thinking of buying a\\n17\" monitor and was going to consider the Mitsubishi. If I remember\\ncorrectly, I think its viewing area is 16\" measured diagonally.\\n\\nThanks.\\n\\n--\\nMohammad Al-Ansari\\t\\t\\talansari@cs.indiana.edu\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |3       |13.0      |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Model Accuracy: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Apply the pipeline to the sampled data (df_sampled) to get the 'features' column (TF-IDF vectors)\n",
        "processed_data = model.transform(df_sampled)\n",
        "\n",
        "# Extract the \"features\" column as an RDD\n",
        "tdm_rdd = processed_data.select(\"features\").rdd.map(lambda row: row[0])\n",
        "\n",
        "# Convert the RDD of vectors into a numpy array\n",
        "tdm_array = np.array(tdm_rdd.collect())\n",
        "\n",
        "# Convert the numpy array into a DataFrame (this is our Term-Document Matrix)\n",
        "tdm_df = pd.DataFrame(tdm_array)\n",
        "\n",
        "# Show the Term-Document Matrix\n",
        "print(\"Term-Document Matrix (TDM):\")\n",
        "print(tdm_df)\n",
        "\n",
        "# Optional: Display the first few rows of the TDM\n",
        "print(tdm_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaNE2PnVwCkO",
        "outputId": "e50fa65d-83de-42dc-e21a-d4c8e8de91c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term-Document Matrix (TDM):\n",
            "           0         1        2    3         4    5        6         7    \\\n",
            "0     0.000000  0.000000  1.90774  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "1     0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "2     0.000000  0.000000  0.00000  0.0  2.223593  0.0  2.70702  0.000000   \n",
            "3     1.983452  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "4     0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "...        ...       ...      ...  ...       ...  ...      ...       ...   \n",
            "4768  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "4769  1.983452  0.000000  0.00000  0.0  2.223593  0.0  0.00000  0.000000   \n",
            "4770  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "4771  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.00000  0.000000   \n",
            "4772  0.000000  2.504946  0.00000  0.0  0.000000  0.0  0.00000  1.840601   \n",
            "\n",
            "           8         9    ...       990  991       992  993       994  \\\n",
            "0     0.000000  0.000000  ...  2.100533  0.0  2.013873  0.0  4.574994   \n",
            "1     0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "2     6.417494  0.000000  ...  2.100533  0.0  6.041619  0.0  0.000000   \n",
            "3     0.000000  0.000000  ...  2.100533  0.0  0.000000  0.0  0.000000   \n",
            "4     0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "...        ...       ...  ...       ...  ...       ...  ...       ...   \n",
            "4768  0.000000  2.143551  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "4769  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "4770  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  2.287497   \n",
            "4771  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "4772  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "\n",
            "           995       996       997  998       999  \n",
            "0     0.000000  0.000000  0.000000  0.0  2.504946  \n",
            "1     0.000000  0.000000  0.000000  0.0  0.000000  \n",
            "2     0.000000  0.000000  2.455706  0.0  0.000000  \n",
            "3     4.300332  1.659904  0.000000  0.0  0.000000  \n",
            "4     0.000000  0.000000  0.000000  0.0  0.000000  \n",
            "...        ...       ...       ...  ...       ...  \n",
            "4768  0.000000  0.000000  2.455706  0.0  0.000000  \n",
            "4769  0.000000  0.000000  0.000000  0.0  0.000000  \n",
            "4770  0.000000  1.659904  0.000000  0.0  0.000000  \n",
            "4771  0.000000  0.000000  0.000000  0.0  0.000000  \n",
            "4772  0.000000  0.000000  0.000000  0.0  0.000000  \n",
            "\n",
            "[4773 rows x 1000 columns]\n",
            "        0    1        2    3         4    5        6    7         8    9    \\\n",
            "0  0.000000  0.0  1.90774  0.0  0.000000  0.0  0.00000  0.0  0.000000  0.0   \n",
            "1  0.000000  0.0  0.00000  0.0  0.000000  0.0  0.00000  0.0  0.000000  0.0   \n",
            "2  0.000000  0.0  0.00000  0.0  2.223593  0.0  2.70702  0.0  6.417494  0.0   \n",
            "3  1.983452  0.0  0.00000  0.0  0.000000  0.0  0.00000  0.0  0.000000  0.0   \n",
            "4  0.000000  0.0  0.00000  0.0  0.000000  0.0  0.00000  0.0  0.000000  0.0   \n",
            "\n",
            "   ...       990  991       992  993       994       995       996       997  \\\n",
            "0  ...  2.100533  0.0  2.013873  0.0  4.574994  0.000000  0.000000  0.000000   \n",
            "1  ...  0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
            "2  ...  2.100533  0.0  6.041619  0.0  0.000000  0.000000  0.000000  2.455706   \n",
            "3  ...  2.100533  0.0  0.000000  0.0  0.000000  4.300332  1.659904  0.000000   \n",
            "4  ...  0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "   998       999  \n",
            "0  0.0  2.504946  \n",
            "1  0.0  0.000000  \n",
            "2  0.0  0.000000  \n",
            "3  0.0  0.000000  \n",
            "4  0.0  0.000000  \n",
            "\n",
            "[5 rows x 1000 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxeRwWPGwGGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}