{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPbDCtco0CPslp1Iun5t5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanalakshmi3149/diabatics/blob/main/beziris_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMBGu_Nzmck9",
        "outputId": "2adc49ce-598b-420a-8da7-dcf9dc581c20"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every package has to install each time googlecolab runs jyputernoot book.\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bupDydBUlgPB",
        "outputId": "ff7c3cc2-473c-4e70-d560-d0e7987c50e4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('drive/My Drive/Colab Notebooks/bezdekIris.data',inferSchema=True, header =True)\\\n",
        ".toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"label\")\n",
        "\n",
        "dataset.select('label').distinct().show(10)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4S7rE0enMlw",
        "outputId": "3d043866-9629-4bf2-b754-f6bbf85dd008"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|          label|\n",
            "+---------------+\n",
            "| Iris-virginica|\n",
            "|    Iris-setosa|\n",
            "|Iris-versicolor|\n",
            "+---------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vector_assembler = VectorAssembler(\\\n",
        "inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"],\\\n",
        "outputCol=\"features\")\n",
        "df_temp = vector_assembler.transform(dataset)\n",
        "df_temp.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9MlMXCGn25A",
        "outputId": "f987e873-167a-453d-cd76-6fb8a23ef12a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Letâ€™s remove unnecessary columns:\n",
        "df = df_temp.drop('sep_len', 'sep_wid', 'pet_len', 'pet_wid')\n",
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaOsWC8-oHf3",
        "outputId": "414fa1c1-5cc7-43f5-d231-e6aa62c89606"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|      label|         features|\n",
            "+-----------+-----------------+\n",
            "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "+-----------+-----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
        "df = l_indexer.fit(df).transform(df)\n",
        "\n",
        "\n",
        "df.select('label','labelIndex').distinct().show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm6FBg6QoU73",
        "outputId": "6fedf606-5e71-49b5-c063-8b224f1e23f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+\n",
            "|          label|labelIndex|\n",
            "+---------------+----------+\n",
            "|Iris-versicolor|       0.0|\n",
            "| Iris-virginica|       1.0|\n",
            "|    Iris-setosa|       2.0|\n",
            "+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "FYOGx3X3oiwu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "dt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\",impurity='entropy', maxDepth=4,seed=1234)\n",
        "model = dt.fit(trainingData)\n",
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "dWIiUpDqooXm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test accuracy =  \" , accuracy)\n",
        "print(model.toDebugString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkzPVMT3otQP",
        "outputId": "97c9ec37-455e-4448-de86-f835fb27c3d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9545454545454546\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_a28bb00abf19, depth=4, numNodes=11, numClasses=3, numFeatures=4\n",
            "  If (feature 2 <= 2.45)\n",
            "   Predict: 2.0\n",
            "  Else (feature 2 > 2.45)\n",
            "   If (feature 3 <= 1.75)\n",
            "    If (feature 2 <= 4.95)\n",
            "     If (feature 0 <= 4.95)\n",
            "      Predict: 1.0\n",
            "     Else (feature 0 > 4.95)\n",
            "      Predict: 0.0\n",
            "    Else (feature 2 > 4.95)\n",
            "     If (feature 3 <= 1.55)\n",
            "      Predict: 1.0\n",
            "     Else (feature 3 > 1.55)\n",
            "      Predict: 0.0\n",
            "   Else (feature 3 > 1.75)\n",
            "    Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is code for multiple classification using logistic Regression\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
        "lr = LogisticRegression(maxIter=100, \\\n",
        "\n",
        "                        featuresCol=\"features\", \\\n",
        "\n",
        "                        labelCol='labelIndex')\n",
        "ovr = OneVsRest(classifier=lr, \\\n",
        "                labelCol='labelIndex', \\\n",
        "                featuresCol='features')\n",
        "#from pyspark.ml import Pipeline\n",
        "#pipeline_ovr = Pipeline(stages=[vecAssembler, stdScaler, ovr])\n",
        "#pipelineModel_ovr = pipeline_ovr.fit(trainDF)\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "predictionsovr = ovrModel.transform(test)\n",
        "\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictionsovr)\n",
        "print(\"Test accuracy =  \" , accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HkXLz9qpFSG",
        "outputId": "d943d208-0035-47b4-bee3-ecaef2628ebf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9361702127659575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtUwulp4qdMc"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}